# Sistema de Backup InfluxDB - Procesamiento Campo por Campo con Paralelizaci√≥n Avanzada

**Soluci√≥n empresarial de backup para InfluxDB con procesamiento paralelo optimizado y aislamiento completo de datos**

## **Caracter√≠sticas Principales**

### **Seguridad M√°xima**
- **Aislamiento completo**: Cada campo se procesa de forma independiente
- **Prevenci√≥n de contaminaci√≥n cruzada**: Los timestamps de diferentes campos nunca se mezclan
- **Transacciones at√≥micas**: Garantiza integridad de datos en caso de fallo
- **Rollback autom√°tico**: Recuperaci√≥n completa ante errores cr√≠ticos

### **Alto Rendimiento**
- **Procesamiento paralelo**: M√∫ltiples campos procesados simult√°neamente
- **Optimizaci√≥n de memoria**: Gesti√≥n inteligente de buffers por worker
- **Batch processing**: Agrupaci√≥n eficiente de inserts para m√°ximo throughput
- **Pool de conexiones**: Reutilizaci√≥n optimizada de conexiones InfluxDB
- **Monitoreo en tiempo real**: M√©tricas detalladas de rendimiento

### **Configuraci√≥n Flexible**
- **YAML declarativo**: Configuraci√≥n clara y mantenible
- **M√∫ltiples bases de datos**: Soporte simult√°neo para varios or√≠genes
- **Filtrado avanzado**: Por rangos de tiempo, campos espec√≠ficos o mediciones
- **Programaci√≥n autom√°tica**: Integraci√≥n con APScheduler para ejecuciones peri√≥dicas
- **Logging granular**: Trazabilidad completa de operaciones

## **Arquitectura del Sistema**

```mermaid
graph TB
    subgraph "üèóÔ∏è Capa de Configuraci√≥n"
        CM[ConfigManager]
        YC[YAML Config]
    end

    subgraph "üéõÔ∏è Capa de Orquestaci√≥n"
        BO[BackupOrchestrator]
        AS[APScheduler]
    end

    subgraph "‚ö° Capa de Procesamiento"
        BP[BackupProcessor]
        PW1[Worker Campo 1]
        PW2[Worker Campo 2]
        PWN[Worker Campo N]
    end

    subgraph "üíæ Capa de Datos"
        IC[InfluxDBClient]
        SRC[(Source DB)]
        DST[(Backup DB)]
    end

    subgraph "üìä Capa de Monitoreo"
        LM[LoggerManager]
        MT[M√©tricas]
        AL[Alertas]
    end

    YC --> CM
    CM --> BO
    AS --> BO
    BO --> BP

    BP --> PW1
    BP --> PW2
    BP --> PWN

    PW1 --> IC
    PW2 --> IC
    PWN --> IC

    IC --> SRC
    IC --> DST

    BP --> LM
    LM --> MT
    LM --> AL

    style CM fill:#e1f5fe
    style BO fill:#f3e5f5
    style BP fill:#e8f5e8
    style IC fill:#fff3e0
    style LM fill:#fce4ec
```

---

## **Configuraci√≥n Detallada**

### Estructura del Archivo YAML

```yaml
# Configuraci√≥n principal del sistema
version: "1.0"
app_name: "InfluxDB Field Backup System"

# Configuraci√≥n de logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    console:
      enabled: true
      level: "INFO"
    file:
      enabled: true
      level: "DEBUG"
      filename: "logs/backup_{timestamp}.log"
      max_bytes: 10485760  # 10MB
      backup_count: 5

# Configuraciones de base de datos
databases:
  source:
    host: "localhost"
    port: 8086
    username: "admin"
    password: "password"
    database: "iot_sensors"
    ssl: false
    verify_ssl: false
    timeout: 30
    retries: 3

  backup:
    host: "localhost"
    port: 8087
    username: "backup_user"
    password: "backup_pass"
    database: "iot_sensors_backup"
    ssl: false
    verify_ssl: false
    timeout: 30
    retries: 3

# Configuraci√≥n de procesamiento
processing:
  # N√∫mero de workers paralelos (uno por campo)
  max_workers: 4

  # Tama√±o de lote para inserts
  batch_size: 1000

  # Intervalo entre lotes (segundos)
  batch_interval: 0.1

  # Buffer de memoria por worker (MB)
  worker_memory_limit: 256

  # Timeout por operaci√≥n (segundos)
  operation_timeout: 300

# Configuraci√≥n de backup espec√≠fica
backup:
  # Mediciones a procesar
  measurements:
    - name: "temperature_data"
      fields: ["value", "quality"]
      start_time: "2023-01-01T00:00:00Z"
      end_time: "2023-12-31T23:59:59Z"

    - name: "pressure_data"
      fields: ["value", "status"]
      start_time: "2023-06-01T00:00:00Z"
      # end_time no especificado = hasta ahora

  # Configuraci√≥n de chunks temporales
  time_chunks:
    size: "1h"      # Tama√±o de chunk: 1h, 1d, 1w
    overlap: "1m"   # Solapamiento entre chunks

  # Configuraci√≥n de reintentos
  retry:
    max_attempts: 3
    backoff_factor: 2
    max_backoff: 60

# Configuraci√≥n de programaci√≥n autom√°tica
scheduler:
  enabled: true
  timezone: "UTC"

  jobs:
    - id: "daily_backup"
      trigger: "cron"
      hour: 2
      minute: 0
      enabled: true

    - id: "weekly_full_backup"
      trigger: "cron"
      day_of_week: "sun"
      hour: 1
      minute: 0
      enabled: false

# Configuraci√≥n de monitoreo
monitoring:
  metrics:
    enabled: true
    interval: 30  # segundos

  alerts:
    enabled: true
    thresholds:
      error_rate: 0.05    # 5% de errores
      memory_usage: 0.80  # 80% de memoria
      duration: 3600      # 1 hora m√°ximo
```

---

## **Prevenci√≥n de Contaminaci√≥n Cruzada**

### Problema Original

**ANTES** (Contaminaci√≥n):
```mermaid
sequenceDiagram
    participant B as BackupProcessor
    participant I as InfluxDB Source
    participant T as Target DB

    Note over B: ‚ùå Problema: Shared State
    B->>I: "SELECT last_timestamp FROM all_fields"
    I->>B: "2023-12-01T10:30:00Z (Irradiance)"

    Note over B: Usa timestamp de Irradiance para Temperature
    B->>I: "SELECT * FROM Temperature WHERE time > 2023-12-01T10:30:00Z"
    I->>I: Inicia desde timestamp de Temperature INCORRECTO
    I->>B: Datos desde 10:30 (se salta datos anteriores)
    B->>T: Inserta datos incompletos
    T->>T: Se salta datos de Temperature CR√çTICOS
```

**AHORA** (Aislamiento Completo):
```mermaid
sequenceDiagram
    participant BP as BackupProcessor
    participant W1 as Worker Irradiance
    participant W2 as Worker Temperature
    participant I as InfluxDB Source
    participant T as Target DB

    Note over BP: Campo por campo, aislado
    BP->>W1: Procesar Irradiance
    BP->>W2: Procesar Temperature

    W1->>I: "SELECT last_timestamp FROM Irradiance"
    I-->>W1: 2023-12-01T10:30:00Z (solo Irradiance) CORRECTO

    W2->>I: "SELECT last_timestamp FROM Temperature"
    I-->>W2: 2023-11-28T15:45:00Z (solo Temperature) CORRECTO

    parallel
        W1->>T: Procesa Irradiance desde 10:30
    and
        W2->>T: Procesa Temperature desde 15:45
    end
```

### Implementaci√≥n del Aislamiento

```python
class FieldWorker:
    def __init__(self, measurement: str, field: str):
        self.measurement = measurement
        self.field = field
        self.last_timestamp = None  # Estado aislado por campo

    def get_last_timestamp(self) -> Optional[datetime]:
        """Obtiene el √∫ltimo timestamp espec√≠fico para este campo"""
        query = f"""
        SELECT last({self.field}), time
        FROM {self.measurement}
        WHERE {self.field} IS NOT NULL
        """
        # Solo para este campo espec√≠fico
        return self.client.query(query)

    def process_field_data(self):
        """Procesa solo datos de este campo espec√≠fico"""
        start_time = self.get_last_timestamp() or self.config_start_time

        query = f"""
        SELECT time, {self.field}
        FROM {self.measurement}
        WHERE time > '{start_time}'
        AND {self.field} IS NOT NULL
        ORDER BY time ASC
        """

        # Procesamiento aislado
        for batch in self.client.query_chunked(query):
            self.process_batch(batch)
```

---

## **Procesamiento Paralelo Campo por Campo**

### Arquitectura de Workers

```mermaid
graph TB
    subgraph "üéØ BackupProcessor"
        BP[Coordinador Principal]
        Q[Cola de Tareas]
        M[Monitor de Progreso]
    end

    subgraph "‚ö° Pool de Workers"
        W1[Worker 1<br/>temperature.value]
        W2[Worker 2<br/>temperature.quality]
        W3[Worker 3<br/>pressure.value]
        W4[Worker 4<br/>pressure.status]
    end

    subgraph "üíæ Recursos Compartidos"
        CP[Pool Conexiones]
        MM[Memory Manager]
        LG[Logger]
    end

    subgraph "üìä Base de Datos"
        SRC[(Source InfluxDB)]
        TGT[(Target InfluxDB)]
    end

    BP --> Q
    Q --> W1
    Q --> W2
    Q --> W3
    Q --> W4

    W1 --> CP
    W2 --> CP
    W3 --> CP
    W4 --> CP

    CP --> SRC
    CP --> TGT

    W1 --> MM
    W2 --> MM
    W3 --> MM
    W4 --> MM

    W1 --> LG
    W2 --> LG
    W3 --> LG
    W4 --> LG

    M --> BP

    style BP fill:#e3f2fd
    style W1 fill:#e8f5e8
    style W2 fill:#e8f5e8
    style W3 fill:#e8f5e8
    style W4 fill:#e8f5e8
    style CP fill:#fff3e0
    style SRC fill:#f3e5f5
    style TGT fill:#f3e5f5
```

---

## **Gu√≠a de Uso**

### Instalaci√≥n

```bash
# Clonar el repositorio
git clone https://github.com/usuario/backup-influxdb.git
cd backup-influxdb

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar archivo de configuraci√≥n
cp config/backup_config.yaml.template config/backup_config.yaml
# Editar config/backup_config.yaml con tus configuraciones
```

### Configuraci√≥n B√°sica

1. **Configurar conexiones de base de datos**:
```yaml
databases:
  source:
    host: "tu-influxdb-source.com"
    port: 8086
    username: "tu_usuario"
    password: "tu_password"
    database: "tu_database"

  backup:
    host: "tu-influxdb-backup.com"
    port: 8086
    username: "backup_usuario"
    password: "backup_password"
    database: "backup_database"
```

2. **Definir mediciones y campos**:
```yaml
backup:
  measurements:
    - name: "sensor_data"
      fields: ["temperature", "humidity", "pressure"]
      start_time: "2023-01-01T00:00:00Z"
```

### Ejecuci√≥n

```bash
# Ejecuci√≥n simple
python main.py --config config/backup_config.yaml

# Con logging detallado
python main.py --config config/backup_config.yaml --log-level DEBUG

# Backup espec√≠fico por medici√≥n
python main.py --config config/backup_config.yaml --measurement sensor_data

# Backup por rango de fechas
python main.py --config config/backup_config.yaml \
  --start-time "2023-01-01T00:00:00Z" \
  --end-time "2023-01-31T23:59:59Z"
```

---

## **Ejemplos de Configuraci√≥n**

### Configuraci√≥n B√°sica para IoT

```yaml
version: "1.0"
app_name: "IoT Sensors Backup"

databases:
  source:
    host: "iot-influxdb.local"
    port: 8086
    database: "iot_sensors"

  backup:
    host: "backup-influxdb.local"
    port: 8086
    database: "iot_sensors_backup"

backup:
  measurements:
    - name: "temperature_sensors"
      fields: ["value", "quality_flag"]
      start_time: "2023-01-01T00:00:00Z"

    - name: "humidity_sensors"
      fields: ["value", "calibration_offset"]
      start_time: "2023-01-01T00:00:00Z"

processing:
  max_workers: 2
  batch_size: 500
  batch_interval: 0.2
```

### Configuraci√≥n Avanzada para Producci√≥n

```yaml
version: "1.0"
app_name: "Production Backup System"

logging:
  level: "INFO"
  handlers:
    file:
      enabled: true
      filename: "logs/backup_{timestamp}.log"
      max_bytes: 52428800  # 50MB
      backup_count: 10

databases:
  source:
    host: "prod-influxdb-cluster.com"
    port: 8086
    username: "backup_service"
    password: "${INFLUX_PASSWORD}"
    database: "production_metrics"
    ssl: true
    verify_ssl: true
    timeout: 60
    retries: 5

processing:
  max_workers: 8
  batch_size: 2000
  worker_memory_limit: 512
  operation_timeout: 600

backup:
  measurements:
    - name: "system_metrics"
      fields: ["cpu_usage", "memory_usage", "disk_io", "network_io"]
      start_time: "2023-01-01T00:00:00Z"

  time_chunks:
    size: "6h"
    overlap: "5m"

  retry:
    max_attempts: 5
    backoff_factor: 3
    max_backoff: 300

scheduler:
  enabled: true
  jobs:
    - id: "hourly_incremental"
      trigger: "cron"
      minute: 0

    - id: "daily_full_check"
      trigger: "cron"
      hour: 3
      minute: 0

monitoring:
  metrics:
    enabled: true
    interval: 15

  alerts:
    enabled: true
    thresholds:
      error_rate: 0.02
      memory_usage: 0.85
      duration: 7200
```

---

## **Configuraci√≥n Avanzada**

### Variables de Entorno

```bash
# Archivo .env
INFLUX_SOURCE_HOST=localhost
INFLUX_SOURCE_PORT=8086
INFLUX_SOURCE_USER=admin
INFLUX_SOURCE_PASS=secret123

INFLUX_BACKUP_HOST=localhost
INFLUX_BACKUP_PORT=8087
INFLUX_BACKUP_USER=backup
INFLUX_BACKUP_PASS=backup456

# Configuraci√≥n de logging
LOG_LEVEL=INFO
LOG_FILE_PATH=logs/
LOG_MAX_SIZE=10MB
LOG_BACKUP_COUNT=5

# Configuraci√≥n de procesamiento
MAX_WORKERS=4
BATCH_SIZE=1000
MEMORY_LIMIT=256MB
OPERATION_TIMEOUT=300
```

### Uso en Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

# Configuraci√≥n por defecto
ENV LOG_LEVEL=INFO
ENV MAX_WORKERS=4
ENV BATCH_SIZE=1000

CMD ["python", "main.py", "--config", "config/backup_config.yaml"]
```

```yaml
# docker-compose.yml
version: '3.8'
services:
  backup-service:
    build: .
    environment:
      - INFLUX_SOURCE_HOST=influxdb-source
      - INFLUX_BACKUP_HOST=influxdb-backup
      - LOG_LEVEL=DEBUG
    volumes:
      - ./logs:/app/logs
      - ./config:/app/config
    depends_on:
      - influxdb-source
      - influxdb-backup
```

---

## **Troubleshooting**

### Problemas Comunes

1. **Error de conexi√≥n a InfluxDB**
```
ERROR: Could not connect to InfluxDB at localhost:8086
```
**Soluci√≥n**: Verificar que InfluxDB est√© ejecut√°ndose y sea accesible
```bash
curl -i http://localhost:8086/ping
```

2. **Memoria insuficiente**
```
WARNING: Worker memory limit exceeded (256MB)
```
**Soluci√≥n**: Ajustar configuraci√≥n de memoria o reducir batch_size
```yaml
processing:
  worker_memory_limit: 512  # Aumentar l√≠mite
  batch_size: 500          # Reducir tama√±o de lote
```

3. **Timeout en operaciones**
```
ERROR: Operation timeout after 300 seconds
```
**Soluci√≥n**: Aumentar timeout o dividir en chunks m√°s peque√±os
```yaml
processing:
  operation_timeout: 600
backup:
  time_chunks:
    size: "30m"  # Chunks m√°s peque√±os
```

4. **Contaminaci√≥n de timestamps**
```
WARNING: Timestamp inconsistency detected
```
**Soluci√≥n**: El sistema previene esto autom√°ticamente con aislamiento de campos

### Logging y Depuraci√≥n

```python
# Activar logging detallado
import logging
logging.getLogger('influxdb_backup').setLevel(logging.DEBUG)

# Ver progreso en tiempo real
python main.py --config config/backup_config.yaml --verbose

# Verificar configuraci√≥n
python -c "
from src.classes.config_manager import ConfigManager
config = ConfigManager('config/backup_config.yaml')
print(config.get_summary())
"
```

### Verificaci√≥n de Integridad

```python
# Script de verificaci√≥n post-backup
from src.classes.influxdb_client import InfluxDBClient

source = InfluxDBClient(source_config)
backup = InfluxDBClient(backup_config)

# Comparar conteos por campo
for measurement in measurements:
    for field in fields:
        source_count = source.count_field_records(measurement, field)
        backup_count = backup.count_field_records(measurement, field)
        print(f"{measurement}.{field}: {source_count} vs {backup_count}")
```

---

## **Monitoreo y M√©tricas**

### M√©tricas Disponibles

- **Rendimiento**: Records/segundo, memoria utilizada, tiempo de ejecuci√≥n
- **Calidad**: Tasa de errores, reintentos, datos perdidos
- **Sistema**: CPU, memoria, conexiones de red
- **Negocio**: Campos procesados, mediciones completadas, cobertura temporal

### Dashboard de Monitoreo

```python
# M√©tricas en tiempo real
{
    "performance": {
        "records_per_second": 1250,
        "memory_usage_mb": 180,
        "active_workers": 4,
        "queue_size": 0
    },
    "quality": {
        "error_rate": 0.01,
        "retry_count": 3,
        "success_rate": 0.99
    },
    "progress": {
        "measurements_completed": 8,
        "measurements_total": 10,
        "estimated_completion": "2023-12-01T14:30:00Z"
    }
}
```

### Alertas Autom√°ticas

```yaml
monitoring:
  alerts:
    - name: "high_error_rate"
      condition: "error_rate > 0.05"
      action: "email"
      recipients: ["admin@company.com"]

    - name: "memory_pressure"
      condition: "memory_usage > 0.90"
      action: "reduce_workers"

    - name: "long_running_job"
      condition: "duration > 3600"
      action: "notification"
```

---

## **Flujo de Desarrollo**

### Estructura del Proyecto

```
backup-influxdb/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ classes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backup_orchestrator.py    # Orquestador principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backup_processor.py       # Procesador con workers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config_manager.py         # Gesti√≥n de configuraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ influxdb_client.py        # Cliente InfluxDB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger_manager.py         # Sistema de logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ apscheduler_backup.py     # Programaci√≥n autom√°tica
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                      # Utilidades
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ backup_config.yaml.template   # Plantilla de configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ backup_config.yaml           # Configuraci√≥n actual
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ unit/                        # Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ integration/                 # Tests de integraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ performance/                 # Tests de rendimiento
‚îú‚îÄ‚îÄ logs/                           # Logs del sistema
‚îú‚îÄ‚îÄ docs/                           # Documentaci√≥n
‚îú‚îÄ‚îÄ scripts/                        # Scripts de utilidad
‚îú‚îÄ‚îÄ main.py                         # Punto de entrada
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias
‚îú‚îÄ‚îÄ Dockerfile                      # Imagen Docker
‚îú‚îÄ‚îÄ docker-compose.yaml            # Orquestaci√≥n
‚îî‚îÄ‚îÄ README.md                       # Documentaci√≥n principal
```

### Comandos de Desarrollo

```bash
# Tests
python -m pytest test/ -v
python -m pytest test/unit/ -v
python -m pytest test/integration/ -v --slow

# Linting
flake8 src/
black src/
isort src/

# Coverage
python -m pytest test/ --cov=src --cov-config=test/.coveragerc --cov-report=html

# Profiling
python -m cProfile -s cumtime main.py --config config/backup_config.yaml

# Docker
docker build -t backup-influxdb .
docker-compose up -d
docker-compose logs -f backup-service
```

### Contribuci√≥n

1. Fork del repositorio
2. Crear rama de feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit de cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

### Consideraciones de Seguridad

- Nunca hardcodear credenciales en el c√≥digo
- Usar variables de entorno para informaci√≥n sensible
- Validar y sanitizar todas las entradas
- Implementar logging de auditor√≠a para operaciones cr√≠ticas
- Mantener dependencias actualizadas

### Tips de Rendimiento

- Ajustar `max_workers` seg√∫n CPU disponible
- Optimizar `batch_size` para tu caso de uso
- Monitorear uso de memoria con `worker_memory_limit`
- Usar chunks temporales apropiados para el volumen de datos
- Implementar pooling de conexiones para m√∫ltiples bases

**Sistema de Backup InfluxDB - Procesamiento Campo por Campo con Paralelizaci√≥n Avanzada**
