# InfluxDB Backup System
## Sistema de Backup Campo por Campo con Paralelizaci√≥n Configurable

Sistema robusto de backup para InfluxDB 1.8 que implementa **procesamiento campo por campo independiente** con **paralelizaci√≥n configurable** para m√°xima seguridad e integridad de datos.

## üéØ **Caracter√≠sticas Principales**

### ‚úÖ **Seguridad M√°xima**
- **Procesamiento campo por campo**: Cada campo se procesa independientemente
- **Prevenci√≥n de contaminaci√≥n cruzada**: Timestamps espec√≠ficos por campo
- **Aislamiento completo**: Errores en un campo no afectan otros
- **Validaci√≥n granular**: Verificaci√≥n independiente por campo

### ‚ö° **Alto Rendimiento**
- **Paralelizaci√≥n configurable**: 1-16+ workers simult√°neos
- **ThreadPoolExecutor**: Gesti√≥n eficiente de hilos
- **M√©tricas en tiempo real**: Monitoreo de eficiencia paralela
- **Optimizaci√≥n autom√°tica**: Balanceo de carga din√°mico

### üîß **Configuraci√≥n Flexible**
- **Archivos YAML independientes**: Un archivo por proceso de backup
- **Filtrado avanzado**: Por medici√≥n, campo y tipo de dato
- **Modos de backup**: Incremental con scheduler y range espec√≠fico
- **Logging avanzado**: Thread-safe con identificadores √∫nicos

---

## üèóÔ∏è **Arquitectura del Sistema**

### **Diagrama General**

```mermaid
graph TB
    subgraph "Sistema Principal"
        A[main.py<br/>Orchestrator]
        B[ConfigManager<br/>Validaci√≥n YAML]
        C[BackupProcessor<br/>Coordinador]
    end

    subgraph "Procesamiento Paralelo"
        D[ThreadPoolExecutor]
        E1[Worker Thread T01<br/>Campo: Irradiance]
        E2[Worker Thread T02<br/>Campo: Temperature]
        E3[Worker Thread T03<br/>Campo: Humidity]
        En[Worker Thread Tn<br/>Campo: N]
    end

    subgraph "Clientes InfluxDB"
        F[InfluxDBClient Source]
        G[InfluxDBClient Destination]
    end

    subgraph "Datos"
        H[(InfluxDB Source<br/>Gomera_Alojera)]
        I[(InfluxDB Destination<br/>Gomera_Alojera)]
    end

    A --> B
    B --> C
    C --> D
    D --> E1
    D --> E2
    D --> E3
    D --> En
    E1 --> F
    E2 --> F
    E3 --> F
    En --> F
    E1 --> G
    E2 --> G
    E3 --> G
    En --> G
    F --> H
    G --> I

    style E1 fill:#e1f5fe
    style E2 fill:#f3e5f5
    style E3 fill:#e8f5e8
    style En fill:#fff3e0
```

### **Flujo de Procesamiento Campo por Campo**

```mermaid
sequenceDiagram
    participant M as main.py
    participant CM as ConfigManager
    participant BP as BackupProcessor
    participant TPE as ThreadPoolExecutor
    participant T1 as Thread T01<br/>(Campo 1)
    participant T2 as Thread T02<br/>(Campo 2)
    participant SC as SourceClient
    participant DC as DestClient

    Note over M: 1. Inicio del Sistema
    M->>CM: Cargar irr.yaml
    CM->>CM: Validar configuraci√≥n
    CM->>BP: Crear BackupProcessor

    Note over BP: 2. Preparaci√≥n del Backup
    BP->>SC: Conectar a Source InfluxDB
    BP->>DC: Conectar a Dest InfluxDB
    BP->>DC: Crear base de datos destino

    Note over BP: 3. An√°lisis de Medici√≥n
    BP->>SC: get_field_keys("ForecastingWeather")
    SC-->>BP: {WRF_continuous_Irradiance_W_m2: numeric, WRF_continuous_Temperature_2m_degC: numeric}
    BP->>BP: _filter_fields() ‚Üí Solo campos configurados

    Note over BP: 4. Procesamiento Paralelo
    BP->>TPE: Crear ThreadPoolExecutor(max_workers=4)

    loop Para cada campo filtrado
        BP->>TPE: submit(_backup_single_field, campo, T_ID)
    end

    Note over T1, T2: 5. Procesamiento Independiente por Campo

    par Campo 1: WRF_continuous_Irradiance_W_m2
        T1->>DC: get_field_last_timestamp("Irradiance")
        DC-->>T1: 2023-12-01T10:30:00Z
        T1->>T1: Calcular start_time = timestamp + 1Œºs
        T1->>SC: query_data(campo="Irradiance", start_time)
        SC-->>T1: [datos desde 2023-12-01T10:30:00.000001Z]
        T1->>DC: write_data(datos)
        T1-->>TPE: SUCCESS: 1500 registros
    and Campo 2: WRF_continuous_Temperature_2m_degC
        T2->>DC: get_field_last_timestamp("Temperature")
        DC-->>T2: 2023-11-28T15:45:00Z
        T2->>T2: Calcular start_time = timestamp + 1Œºs
        T2->>SC: query_data(campo="Temperature", start_time)
        SC-->>T2: [datos desde 2023-11-28T15:45:00.000001Z]
        T2->>DC: write_data(datos)
        T2-->>TPE: SUCCESS: 2300 registros
    end

    Note over TPE: 6. Recolecci√≥n de Resultados
    TPE->>BP: as_completed() ‚Üí Resultados por campo
    BP->>BP: _update_parallel_stats()
    BP->>BP: Generar resumen

    Note over BP: 7. Finalizaci√≥n
    BP-->>M: {success: true, stats: {...}}
    M->>M: Mostrar resumen final
```

---

## üîß **Configuraci√≥n Detallada**

### **Estructura de Proyecto**

```
backup-influxdb/
‚îú‚îÄ‚îÄ main.py                          # Orchestrator principal
‚îú‚îÄ‚îÄ src/                            # M√≥dulos del sistema
‚îÇ   ‚îú‚îÄ‚îÄ backup_processor.py         # Procesador campo por campo
‚îÇ   ‚îú‚îÄ‚îÄ config_manager.py          # Gestor de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ influxdb_client.py         # Cliente InfluxDB con get_field_last_timestamp()
‚îÇ   ‚îú‚îÄ‚îÄ logger_manager.py          # Logging thread-safe
‚îÇ   ‚îú‚îÄ‚îÄ apscheduler_backup.py      # Scheduler para modo incremental
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                   # Utilidades
‚îú‚îÄ‚îÄ config/                        # Configuraciones independientes
‚îÇ   ‚îú‚îÄ‚îÄ irr.yaml                   # Backup de campo Irradiance
‚îÇ   ‚îú‚îÄ‚îÄ temp.yaml                  # Backup de campo Temperature
‚îÇ   ‚îî‚îÄ‚îÄ backup_config.yaml.template # Template para nuevas configuraciones
‚îú‚îÄ‚îÄ volumes/
‚îÇ   ‚îî‚îÄ‚îÄ logs/                      # Logs con identificadores por thread
‚îî‚îÄ‚îÄ README.md                      # Esta documentaci√≥n
```

### **Configuraciones Actuales**

#### **irr.yaml** - Backup de Irradiancia
```yaml
measurements:
  specific:
    ForecastingWeather:
      fields:
        include: [WRF_continuous_Irradiance_W_m2]  # Solo irradiancia

options:
  backup_mode: incremental
  parallel_workers: 1                             # 1 campo = 1 worker
  incremental:
    schedule: "* * * * *"                         # Cada minuto
  loki:
    tags:
      config: "irr.yaml"                          # Tag √∫nico para logs
```

#### **temp.yaml** - Backup de Temperatura
```yaml
measurements:
  specific:
    ForecastingWeather:
      fields:
        include: [WRF_continuous_Temperature_2m_degC]  # Solo temperatura

options:
  backup_mode: incremental
  parallel_workers: 1                               # 1 campo = 1 worker
  incremental:
    schedule: "* * * * *"                           # Cada minuto
  loki:
    tags:
      config: "temp.yaml"                           # Tag √∫nico para logs
```

### **Par√°metros de Paralelizaci√≥n**

| Par√°metro | Descripci√≥n | Valores Recomendados |
|-----------|-------------|---------------------|
| `parallel_workers` | N√∫mero de hilos para procesar campos | `1`: Secuencial (m√°xima seguridad)<br/>`2-4`: Sistemas normales<br/>`4-8`: Servidores potentes<br/>`8-16`: Hardware dedicado |

---

## üîç **Prevenci√≥n de Contaminaci√≥n Cruzada**

### **Problema Original Resuelto**

**‚ùå ANTES** (Contaminaci√≥n):
```mermaid
sequenceDiagram
    participant I as irr.yaml
    participant T as temp.yaml
    participant DB as InfluxDB

    Note over I, T: Problema: Timestamps globales por medici√≥n

    I->>DB: get_last_timestamp("ForecastingWeather")
    Note right of DB: Devuelve timestamp de CUALQUIER campo
    DB-->>I: 2023-12-01T10:30:00Z (del campo Temperature)
    I->>I: Inicia desde timestamp de Temperature ‚ùå

    T->>DB: get_last_timestamp("ForecastingWeather")
    DB-->>T: 2023-12-01T10:30:00Z (actualizado por irr.yaml)
    T->>T: Se salta datos de Temperature ‚ùå
```

**‚úÖ AHORA** (Aislamiento Completo):
```mermaid
sequenceDiagram
    participant I as irr.yaml
    participant T as temp.yaml
    participant DB as InfluxDB

    Note over I, T: Soluci√≥n: Timestamps espec√≠ficos por campo

    I->>DB: get_field_last_timestamp("ForecastingWeather", "WRF_continuous_Irradiance_W_m2")
    DB-->>I: 2023-12-01T10:30:00Z (solo Irradiance) ‚úÖ
    I->>I: Procesa solo desde su √∫ltimo timestamp

    T->>DB: get_field_last_timestamp("ForecastingWeather", "WRF_continuous_Temperature_2m_degC")
    DB-->>T: 2023-11-28T15:45:00Z (solo Temperature) ‚úÖ
    T->>T: Procesa desde su propio timestamp independiente
```

### **Funcionamiento del Aislamiento**

```mermaid
graph TB
    subgraph "Configuraci√≥n irr.yaml"
        A1[Campo: WRF_continuous_Irradiance_W_m2]
        A2[Timestamp espec√≠fico: 2023-12-01T10:30:00Z]
        A3[Procesa desde: 2023-12-01T10:30:00.000001Z]
    end

    subgraph "Configuraci√≥n temp.yaml"
        B1[Campo: WRF_continuous_Temperature_2m_degC]
        B2[Timestamp espec√≠fico: 2023-11-28T15:45:00Z]
        B3[Procesa desde: 2023-11-28T15:45:00.000001Z]
    end

    subgraph "Base de Datos Destino"
        C[ForecastingWeather]
        C1[Irradiance: √∫ltimo = 2023-12-01T10:30:00Z]
        C2[Temperature: √∫ltimo = 2023-11-28T15:45:00Z]
        C3[Humidity: √∫ltimo = 2023-12-10T08:15:00Z]
    end

    A1 --> A2
    A2 --> A3
    B1 --> B2
    B2 --> B3

    A2 -.->|get_field_last_timestamp| C1
    B2 -.->|get_field_last_timestamp| C2

    style A1 fill:#e1f5fe
    style B1 fill:#f3e5f5
    style C1 fill:#e1f5fe
    style C2 fill:#f3e5f5
    style C3 fill:#e8f5e8
```

---

## ‚ö° **Procesamiento Paralelo Campo por Campo**

### **Diagrama de Threads Independientes**

```mermaid
gantt
    title Procesamiento Paralelo de Campos (parallel_workers: 4)
    dateFormat X
    axisFormat %s

    section Thread T01
    Campo: Irradiance     :active, t1, 0, 8

    section Thread T02
    Campo: Temperature    :active, t2, 1, 6

    section Thread T03
    Campo: Humidity       :active, t3, 2, 7

    section Thread T04
    Campo: Pressure       :active, t4, 3, 5

    section Secuencial (sin paralelizaci√≥n)
    Todos los campos      :crit, seq, 0, 26
```

### **M√©tricas de Paralelizaci√≥n**

El sistema genera autom√°ticamente m√©tricas detalladas:

```
Parallelization metrics:
  ‚Ä¢ Workers used: 4/4
  ‚Ä¢ Avg processing time: 6.2s
  ‚Ä¢ Parallel efficiency: 78.5%
  ‚Ä¢ Thread utilization: [T01, T02, T03, T04]

Field Results Summary:
  ‚Ä¢ Total fields: 4
  ‚Ä¢ Processed: 4
  ‚Ä¢ Skipped: 0
  ‚Ä¢ Failed: 0
  ‚Ä¢ Total records: 15,847
```

---

## üöÄ **Gu√≠a de Uso**

### **1. Instalaci√≥n**

```bash
# Clonar repositorio
git clone <repository-url>
cd backup-influxdb

# Crear estructura de directorios
mkdir -p volumes/logs

# Instalar dependencias
pip install -r requirements.txt
```

### **2. Configuraci√≥n**

```bash
# Copiar template para nueva configuraci√≥n
cp config/backup_config.yaml.template config/mi_backup.yaml

# Editar configuraci√≥n
vim config/mi_backup.yaml
```

### **3. Ejecuci√≥n**

#### **Modo Desarrollo** (validar configuraciones)
```bash
python main.py --validate-only
```

#### **Modo Producci√≥n** (ejecutar backups)
```bash
python main.py --config /config --verbose
```

#### **Con Docker**
```bash
docker-compose up -d
```

### **4. Monitoreo**

#### **Logs por Thread**
```bash
# Ver logs de configuraci√≥n espec√≠fica
tail -f volumes/logs/irr.yaml/backup.log

# Buscar logs de thread espec√≠fico
grep "\[T01\]" volumes/logs/temp.yaml/backup.log
```

#### **M√©tricas en Grafana**
- URL: `http://localhost:3000`
- Usuario: `admin`
- Contrase√±a: `password`
- Dashboard: "InfluxDB Backup Metrics"

---

## üìä **Ejemplos de Configuraci√≥n**

### **Configuraci√≥n de Alto Rendimiento** (M√∫ltiples Campos)

```yaml
# config/high_performance.yaml
measurements:
  specific:
    WeatherData:
      fields:
        include: [
          temperature, humidity, pressure, wind_speed,
          wind_direction, rainfall, solar_radiation, uv_index
        ]

options:
  parallel_workers: 8          # 8 campos en paralelo
  days_of_pagination: 1        # Chunks peque√±os para mayor seguridad
  field_obsolete_threshold: "3M"

  incremental:
    schedule: "0 */6 * * *"     # Cada 6 horas
```

### **Configuraci√≥n de M√°xima Seguridad** (Campo Individual)

```yaml
# config/critical_data.yaml
measurements:
  specific:
    CriticalMetrics:
      fields:
        include: [critical_sensor_reading]  # Solo un campo cr√≠tico

options:
  parallel_workers: 1          # Procesamiento secuencial
  days_of_pagination: 1        # Chunks de 1 d√≠a
  retries: 5                   # 5 intentos en caso de error

  incremental:
    schedule: "* * * * *"       # Cada minuto
```

### **Configuraci√≥n por Rango** (Backup Hist√≥rico)

```yaml
# config/historical_backup.yaml
options:
  backup_mode: range
  parallel_workers: 16         # M√°ximo paralelismo para hist√≥rico

  range:
    start_date: "2023-01-01T00:00:00Z"
    end_date: "2023-12-31T23:59:59Z"
```

---

## üîß **Configuraci√≥n Avanzada**

### **Par√°metros de Rendimiento**

| Par√°metro | Descripci√≥n | Valor por Defecto | Recomendaci√≥n |
|-----------|-------------|-------------------|---------------|
| `parallel_workers` | Hilos para campos | `4` | = N√∫mero de campos a procesar |
| `days_of_pagination` | D√≠as por chunk | `7` | `1-7` seg√∫n volumen de datos |
| `timeout_client` | Timeout HTTP (seg) | `20` | `20-60` seg√∫n latencia |
| `retries` | Reintentos por error | `3` | `3-5` para entornos inestables |

### **Optimizaci√≥n por Escenario**

#### **Pocos Campos, Alto Volumen**
```yaml
parallel_workers: 2-4        # Pocos threads pero eficientes
days_of_pagination: 1        # Chunks peque√±os
timeout_client: 60           # Timeout largo para grandes consultas
```

#### **Muchos Campos, Bajo Volumen**
```yaml
parallel_workers: 8-16       # Muchos threads para paralelismo
days_of_pagination: 30       # Chunks grandes
timeout_client: 20           # Timeout normal
```

#### **Datos Cr√≠ticos**
```yaml
parallel_workers: 1          # Secuencial para m√°xima seguridad
retries: 5                   # Muchos reintentos
field_obsolete_threshold: "" # Sin filtrado por obsolescencia
```

---

## üîç **Troubleshooting**

### **Problemas Comunes**

#### **1. Contaminaci√≥n entre Configuraciones**
```bash
# S√≠ntoma: Configuraciones se saltan datos
# Causa: Tags de Loki duplicados o nombres de campos incorrectos

# Soluci√≥n:
# 1. Verificar tags √∫nicos en loki.tags.config
# 2. Verificar campos espec√≠ficos en measurements.specific.*.fields.include
```

#### **2. Bajo Rendimiento**
```bash
# S√≠ntoma: Procesamiento lento
# Causa: parallel_workers demasiado bajo

# Soluci√≥n:
# 1. Aumentar parallel_workers seg√∫n n√∫mero de campos
# 2. Monitorear uso de CPU y memoria
# 3. Ajustar days_of_pagination
```

#### **3. Errores de Conexi√≥n**
```bash
# S√≠ntoma: "Failed to establish connections"
# Causa: InfluxDB no disponible

# Soluci√≥n:
# 1. Verificar conectividad: curl http://influxdb:8086/ping
# 2. Revisar credenciales en configuraci√≥n
# 3. Aumentar initial_connection_retry_delay
```

### **Logs de Depuraci√≥n**

```bash
# Habilitar debug completo
python main.py --verbose

# Ver threads espec√≠ficos
grep "\[T01\]" volumes/logs/*/backup.log

# Monitorear estad√≠sticas de paralelizaci√≥n
grep "Parallelization metrics" volumes/logs/*/backup.log
```

---

## üìà **Monitoreo y M√©tricas**

### **Dashboard de Grafana**

El sistema incluye dashboards preconfigurados:

1. **Backup Overview**: Estado general de todos los procesos
2. **Field Processing**: M√©tricas por campo individual
3. **Parallel Efficiency**: Estad√≠sticas de paralelizaci√≥n
4. **Error Analysis**: An√°lisis de fallos por thread

### **M√©tricas Clave**

- **Records Transferred**: Registros transferidos por configuraci√≥n
- **Parallel Efficiency**: Eficiencia del paralelismo (0-100%)
- **Thread Utilization**: Uso de threads por proceso
- **Field Processing Time**: Tiempo promedio por campo
- **Error Rate**: Porcentaje de errores por configuraci√≥n

---

## üîÑ **Flujo de Desarrollo**

### **Agregar Nueva Configuraci√≥n**

1. **Crear archivo de configuraci√≥n**:
   ```bash
   cp config/backup_config.yaml.template config/nueva_config.yaml
   ```

2. **Configurar campos espec√≠ficos**:
   ```yaml
   measurements:
     specific:
       TuMedicion:
         fields:
           include: [tu_campo_especifico]
   ```

3. **Configurar paralelizaci√≥n**:
   ```yaml
   options:
     parallel_workers: 2  # Seg√∫n n√∫mero de campos
   ```

4. **Validar configuraci√≥n**:
   ```bash
   python main.py --validate-only
   ```

5. **Ejecutar en modo test**:
   ```bash
   python main.py --config /config
   ```

### **Testing**

```bash
# Tests unitarios
pytest test/unit/

# Tests de integraci√≥n
pytest test/integration/

# Test completo del sistema
python test/run_tests.py
```

---

## üìö **Referencias T√©cnicas**

### **Tecnolog√≠as Utilizadas**

- **Python 3.8+**: Lenguaje principal
- **InfluxDB 1.8**: Base de datos temporal
- **ThreadPoolExecutor**: Paralelizaci√≥n de threads
- **APScheduler**: Programaci√≥n de tareas
- **PyYAML**: Parsing de configuraciones
- **Docker/Docker Compose**: Containerizaci√≥n
- **Grafana**: Visualizaci√≥n de m√©tricas
- **Loki**: Logging centralizado

### **Algoritmos Implementados**

1. **Timestamp Field-Specific**: `get_field_last_timestamp(db, measurement, field)`
2. **Parallel Field Processing**: ThreadPoolExecutor con as_completed()
3. **Cross-Contamination Prevention**: Timestamps independientes por campo
4. **Parallel Efficiency Calculation**: (sequential_time / parallel_time / workers) * 100

### **Patrones de Dise√±o**

- **Factory Pattern**: Creaci√≥n de clientes InfluxDB
- **Observer Pattern**: Sistema de logging con m√∫ltiples handlers
- **Strategy Pattern**: Diferentes modos de backup (incremental/range)
- **Template Pattern**: Estructura com√∫n de configuraci√≥n YAML

---

## üìÑ **Licencia**

Este proyecto est√° licenciado bajo la [MIT License](LICENSE).

---

## ü§ù **Contribuci√≥n**

1. Fork del proyecto
2. Crear rama para feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit de cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

---

## üìû **Soporte**

- **Documentaci√≥n**: [README.md](README.md)
- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Wiki**: [GitHub Wiki](https://github.com/your-repo/wiki)

---

**üöÄ Sistema de Backup InfluxDB - Procesamiento Campo por Campo con Paralelizaci√≥n Avanzada**
