# =====================================================================================
# PLANTILLA DE CONFIGURACIÃ“N - SISTEMA DE BACKUP INFLUXDB
# =====================================================================================
# Sistema de Backup Campo por Campo con ParalelizaciÃ³n Configurable
#
# CARACTERÃSTICAS PRINCIPALES:
# âœ… Procesamiento campo por campo independiente
# âœ… ParalelizaciÃ³n configurable (1-16+ workers)
# âœ… PrevenciÃ³n de contaminaciÃ³n cruzada
# âœ… Timestamps especÃ­ficos por campo
# âœ… Thread-safe logging con identificadores Ãºnicos
# âœ… MÃ©tricas de eficiencia en tiempo real
#
# INSTRUCCIONES DE USO:
# 1. Copia este archivo: cp backup_config.yaml.template mi_backup.yaml
# 2. Personaliza la configuraciÃ³n segÃºn tus necesidades
# 3. Valida la configuraciÃ³n: python main.py --validate-only
# 4. Ejecuta el backup: python main.py --config /config
#
# DOCUMENTACIÃ“N COMPLETA: README.md
# =====================================================================================

# ===================================
# CONFIGURACIÃ“N GLOBAL DEL SISTEMA
# ===================================
global:
  # Red Docker para comunicaciÃ³n entre contenedores
  # IMPORTANTE: Todos los contenedores InfluxDB deben estar en esta red
  #
  # Para crear una red compartida:
  # docker network create influxdb_network
  #
  # Para conectar contenedores existentes:
  # docker network connect influxdb_network nombre_contenedor
  network: influxdb_network

# ========================================
# CONFIGURACIÃ“N SERVIDOR INFLUXDB ORIGEN
# ========================================
source:
  # URL del servidor InfluxDB de origen (OBLIGATORIO)
  #
  # FORMATOS VÃLIDOS:
  # - Contenedor Docker: http://nombre-contenedor:8086
  # - Servidor local: http://localhost:8086
  # - Servidor remoto: http://192.168.1.100:8086
  # - Con SSL: https://mi-servidor.com:8086
  #
  # EJEMPLOS:
  # url: http://sysadmintoolkit-influxdb-dev:8086    # Contenedor Docker
  # url: http://influxdb-production:8086             # Servidor producciÃ³n
  # url: https://metrics.empresa.com:8086            # Servidor externo con SSL
  url: http://source-influxdb:8086

  # ConfiguraciÃ³n SSL/TLS
  ssl: false                    # true si usas HTTPS
  verify_ssl: true             # false para certificados autofirmados

  # ========================================
  # CONFIGURACIÃ“N DE BASES DE DATOS
  # ========================================
  #
  # OPCIÃ“N 1: Respaldar bases de datos especÃ­ficas
  # Especifica exactamente quÃ© bases de datos respaldar
  databases:
    - name: metrics             # Nombre en el servidor origen
      destination: metrics_backup  # Nombre en el servidor destino
    - name: telegraf
      destination: telegraf_backup
    - name: weather_data
      destination: weather_data_backup

  # OPCIÃ“N 2: Respaldar TODAS las bases de datos
  # Descomenta esta lÃ­nea para respaldar todas las BD automÃ¡ticamente:
  # databases: []

  # ========================================
  # PREFIJOS Y SUFIJOS PARA NOMBRES
  # ========================================
  # Ãštil para identificar bases de datos respaldadas
  #
  # EJEMPLOS:
  # prefix: "backup_"    â†’ metrics se convierte en backup_metrics
  # suffix: "_bkp"       â†’ metrics se convierte en metrics_bkp
  # prefix: "prod_", suffix: "_v2" â†’ metrics se convierte en prod_metrics_v2
  prefix: ""
  suffix: ""

  # ========================================
  # AUTENTICACIÃ“N (Opcional)
  # ========================================
  # Deja en blanco si InfluxDB no requiere autenticaciÃ³n
  #
  # EJEMPLO CON AUTENTICACIÃ“N:
  # user: "admin"
  # password: "mi_password_seguro_123"
  user: ""
  password: ""

  # ========================================
  # AGRUPAMIENTO DE CONSULTAS
  # ========================================
  # Controla cÃ³mo se agrupan los datos en las consultas
  #
  # VALORES COMUNES:
  # - "30s": Agrupa datos cada 30 segundos (mÃ¡s consultas, menos memoria)
  # - "1m":  Agrupa datos cada minuto (balance)
  # - "5m":  Agrupa datos cada 5 minutos (menos consultas, mÃ¡s memoria)
  # - "1h":  Agrupa datos cada hora (para datos histÃ³ricos grandes)
  # - "":    Sin agrupamiento (para datasets pequeÃ±os)
  #
  # RECOMENDACIONES:
  # - Datos en tiempo real: "30s" o "1m"
  # - Backups histÃ³ricos: "5m" o "1h"
  # - Datasets pequeÃ±os: "" (sin agrupamiento)
  group_by: ""

# =========================================
# CONFIGURACIÃ“N SERVIDOR INFLUXDB DESTINO
# =========================================
destination:
  # URL del servidor InfluxDB de destino (OBLIGATORIO)
  # Puede ser el mismo servidor que el origen (usando diferentes BD)
  #
  # EJEMPLOS:
  # url: http://backup-influxdb:8086           # Servidor dedicado para backups
  # url: http://sysadmintoolkit-influxdb-dev:8086  # Mismo servidor, diferentes BD
  # url: http://192.168.1.200:8086            # Servidor de backup remoto
  url: http://destination-influxdb:8086

  # ConfiguraciÃ³n SSL/TLS
  ssl: false
  verify_ssl: true

  # AutenticaciÃ³n para el servidor destino (puede ser diferente al origen)
  user: ""
  password: ""

# =============================================
# CONFIGURACIÃ“N DE FILTRADO DE MEDICIONES
# =============================================
measurements:
  # ========================================
  # FILTRADO GLOBAL DE MEDICIONES
  # ========================================
  #
  # OPCIÃ“N 1: Incluir mediciones especÃ­ficas (RECOMENDADO)
  # Solo las mediciones listadas serÃ¡n respaldadas
  include: []
  # EJEMPLO: include: [cpu, memory, disk, network]

  # OPCIÃ“N 2: Excluir mediciones especÃ­ficas
  # Todas las mediciones EXCEPTO las listadas serÃ¡n respaldadas
  exclude: []
  # EJEMPLO: exclude: [debug_logs, temp_data, test_metrics]
  #
  # NOTA: No uses 'include' y 'exclude' al mismo tiempo

  # ========================================
  # CONFIGURACIONES ESPECÃFICAS POR MEDICIÃ“N
  # ========================================
  # AquÃ­ defines el procesamiento detallado para cada mediciÃ³n
  # Â¡ESTA ES LA CLAVE DEL SISTEMA CAMPO POR CAMPO!
  specific:
    # ========================================
    # EJEMPLO 1: PROCESAMIENTO DE MÃ‰TRICAS CPU
    # ========================================
    # Scenario: Quieres solo mÃ©tricas de uso de CPU, no todas las mÃ©tricas
    cpu:
      fields:
        # Incluir solo campos especÃ­ficos de CPU
        include: [usage_user, usage_system, usage_idle, usage_iowait]
        # Excluir campos que no necesitas
        exclude: []
        # Tipos de datos a procesar
        types: [numeric, string, boolean]

    # ========================================
    # EJEMPLO 2: PROCESAMIENTO DE MEMORIA
    # ========================================
    # Scenario: Quieres toda la memoria EXCEPTO campos de cache
    memory:
      fields:
        include: []  # Todos los campos
        # Excluir campos de cache que cambian constantemente
        exclude: [buffer, cached, slab]
        types: [numeric, string]

    # ========================================
    # EJEMPLO 3: DATOS METEOROLÃ“GICOS ESPECÃFICOS
    # ========================================
    # Scenario: Solo un campo especÃ­fico de una mediciÃ³n grande
    ForecastingWeather:
      fields:
        # CAMPO POR CAMPO: Solo procesar temperatura
        include: [WRF_continuous_Temperature_2m_degC]
        exclude: []
        types: [numeric, string, boolean]

    # ========================================
    # EJEMPLO 4: MÃšLTIPLES CAMPOS EN PARALELO
    # ========================================
    # Scenario: Varios campos de la misma mediciÃ³n procesados en paralelo
    WeatherStation:
      fields:
        # MÃºltiples campos que se procesarÃ¡n independientemente
        include: [
          temperature,      # Thread T01
          humidity,         # Thread T02
          pressure,         # Thread T03
          wind_speed,       # Thread T04
          wind_direction,   # Thread T05
          rainfall,         # Thread T06
          solar_radiation,  # Thread T07
          uv_index         # Thread T08
        ]
        exclude: []
        types: [numeric]

    # ========================================
    # EJEMPLO 5: FILTRADO POR TIPO DE DATO
    # ========================================
    # Scenario: Solo quieres datos numÃ©ricos, no strings ni booleanos
    sensor_data:
      fields:
        include: []  # Todos los campos
        exclude: []
        types: [numeric]  # Solo datos numÃ©ricos

    # ========================================
    # EJEMPLO 6: LOGS Y EVENTOS
    # ========================================
    # Scenario: Procesar logs con datos de texto
    application_logs:
      fields:
        include: [level, message, timestamp, source]
        exclude: [debug_info, stack_trace]
        types: [string, boolean]  # Solo texto y flags

# =============================================
# OPCIONES DE BACKUP Y PARALELIZACIÃ“N
# =============================================
options:
  # ========================================
  # MODO DE BACKUP
  # ========================================
  #
  # INCREMENTAL: Copia solo datos nuevos desde la Ãºltima ejecuciÃ³n
  # - Ideal para: Backups continuos, datos en tiempo real
  # - Usa: Timestamps especÃ­ficos por campo para evitar contaminaciÃ³n
  # - Ejecuta: SegÃºn schedule configurado
  #
  # RANGE: Copia datos de un perÃ­odo especÃ­fico
  # - Ideal para: Backups histÃ³ricos, migraciones de datos
  # - Usa: Fechas fijas de inicio y fin
  # - Ejecuta: Una sola vez y termina
  backup_mode: incremental

  # ========================================
  # CONFIGURACIÃ“N MODO RANGE
  # ========================================
  # Solo se usa si backup_mode = "range"
  range:
    # Fechas en formato ISO 8601 (YYYY-MM-DDTHH:MM:SSZ)
    #
    # EJEMPLOS:
    # start_date: "2023-01-01T00:00:00Z"    # AÃ±o completo
    # end_date: "2023-12-31T23:59:59Z"
    #
    # start_date: "2023-12-01T08:00:00Z"    # Un dÃ­a especÃ­fico
    # end_date: "2023-12-01T20:00:00Z"
    start_date: "2023-01-01T00:00:00Z"
    end_date: "2023-12-31T23:59:59Z"

  # ========================================
  # CONFIGURACIÃ“N MODO INCREMENTAL
  # ========================================
  # Solo se usa si backup_mode = "incremental"
  incremental:
    # ExpresiÃ³n CRON para programar ejecuciones automÃ¡ticas
    # Deja vacÃ­o para ejecutar solo una vez
    #
    # EJEMPLOS DE EXPRESIONES CRON:
    # "* * * * *"        # Cada minuto (para testing)
    # "*/5 * * * *"      # Cada 5 minutos
    # "0 * * * *"        # Cada hora
    # "0 */6 * * *"      # Cada 6 horas
    # "0 0 * * *"        # Diario a medianoche
    # "0 2 * * 0"        # Semanal los domingos a las 2 AM
    # "0 1 1 * *"        # Mensual el dÃ­a 1 a la 1 AM
    #
    # FORMATO: "minuto hora dÃ­a_mes mes dÃ­a_semana"
    schedule: ""

  # ========================================
  # CONFIGURACIÃ“N DE CONEXIONES
  # ========================================
  # Timeouts y reintentos para conexiones de red
  timeout_client: 20                    # Timeout por consulta (segundos)
  retries: 3                           # Reintentos en caso de error
  retry_delay: 5                       # Espera entre reintentos (segundos)
  initial_connection_retry_delay: 60   # Espera para reconectar al inicio

  # ========================================
  # CONFIGURACIÃ“N DE PAGINACIÃ“N
  # ========================================
  # Divide consultas grandes en chunks para evitar problemas de memoria
  #
  # VALORES RECOMENDADOS:
  # - 1 dÃ­a: Para bases de datos muy grandes (>100GB)
  # - 7 dÃ­as: Para bases de datos medianas (10-100GB)
  # - 30 dÃ­as: Para bases de datos pequeÃ±as (<10GB)
  days_of_pagination: 7

  # =========================================
  # CONFIGURACIÃ“N DE PARALELIZACIÃ“N
  # =========================================
  # Â¡NUEVA FUNCIONALIDAD PRINCIPAL!
  # NÃºmero de hilos para procesar campos en paralelo
  #
  # CÃ“MO FUNCIONA:
  # - Cada campo se procesa en su propio hilo independiente
  # - Timestamps especÃ­ficos por campo (NO contaminaciÃ³n cruzada)
  # - ThreadPoolExecutor gestiona la concurrencia
  # - Logging con identificadores Ãºnicos por thread ([T01], [T02], etc.)
  #
  # GUÃA DE CONFIGURACIÃ“N:
  #
  # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  # â”‚ CAMPOS A BACKUP â”‚ PARALLEL_WORKERS â”‚ DESCRIPCIÃ“N                     â”‚
  # â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  # â”‚ 1 campo         â”‚ 1                â”‚ Secuencial (mÃ¡xima seguridad)   â”‚
  # â”‚ 2-4 campos      â”‚ 2-4              â”‚ Paralelismo completo            â”‚
  # â”‚ 5-8 campos      â”‚ 4-6              â”‚ Balance rendimiento/recursos    â”‚
  # â”‚ 9+ campos       â”‚ 6-8              â”‚ Alto rendimiento                â”‚
  # â”‚ Servidor potenteâ”‚ 8-16             â”‚ MÃ¡ximo paralelismo              â”‚
  # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  #
  # EJEMPLOS POR ESCENARIO:
  #
  # EJEMPLO A: Un solo campo crÃ­tico
  # parallel_workers: 1
  # measurements.specific.CriticalSensor.fields.include: [sensor_reading]
  #
  # EJEMPLO B: EstaciÃ³n meteorolÃ³gica (8 sensores)
  # parallel_workers: 8
  # measurements.specific.Weather.fields.include: [temp, humidity, pressure, ...]
  #
  # EJEMPLO C: MÃºltiples mediciones con pocos campos cada una
  # parallel_workers: 4  # Balance general
  #
  # IMPORTANTE:
  # - No exceder nÃºmero de CPU cores disponibles
  # - Monitorear uso de memoria con parallel_workers alto
  # - Para testing inicial usar parallel_workers: 1
  parallel_workers: 4

  # ========================================
  # GESTIÃ“N DE CAMPOS OBSOLETOS
  # ========================================
  # Evita procesar campos que ya no reciben datos nuevos
  #
  # FORMATO: nÃºmero + unidad (s, m, h, d, w, M, y)
  # EJEMPLOS:
  # "30d"  - Ignorar campos sin datos en 30 dÃ­as
  # "6M"   - Ignorar campos sin datos en 6 meses
  # "1y"   - Ignorar campos sin datos en 1 aÃ±o
  # ""     - No filtrar por obsolescencia (procesar todo)
  #
  # RECOMENDADO: "6M" para la mayorÃ­a de casos
  field_obsolete_threshold: "6M"

  # ========================================
  # CONFIGURACIÃ“N DE LOGGING
  # ========================================
  log_directory: /var/log/backup_influxdb/

  # RotaciÃ³n automÃ¡tica de logs
  log_rotation:
    enabled: true
    when: 'D'        # D=diario, H=por hora, M=por minuto
    interval: 1      # Cada cuÃ¡nto rotar (1 dÃ­a)
    backup_count: 7  # Mantener 7 archivos histÃ³ricos

  # ConfiguraciÃ³n Loki (logging centralizado)
  loki:
    enabled: true
    url: "sysadmintoolkit-loki-dev"  # Servidor Loki
    port: 3100
    # IMPORTANTE: Usar tags Ãºnicos para distinguir configuraciones
    tags:
      app: "influxdb-backup"
      environment: "production"
      config: "mi_backup.yaml"  # Â¡CAMBIAR POR NOMBRE REAL DEL ARCHIVO!

  # Nivel de detalle de logs
  # DEBUG: Muy detallado (para desarrollo)
  # INFO: Normal (recomendado para producciÃ³n)
  # WARNING: Solo advertencias y errores
  # ERROR: Solo errores crÃ­ticos
  log_level: INFO

# =============================================
# EJEMPLOS DE CONFIGURACIONES COMPLETAS
# =============================================

# ========================================
# CONFIGURACIÃ“N TIPO A: CAMPO ÃšNICO CRÃTICO
# ========================================
# Use case: Backup de un sensor crÃ­tico especÃ­fico
#
# measurements:
#   include: [CriticalSensors]
#   specific:
#     CriticalSensors:
#       fields:
#         include: [reactor_temperature]  # Solo temperatura del reactor
#
# options:
#   backup_mode: incremental
#   parallel_workers: 1                  # Secuencial para mÃ¡xima seguridad
#   incremental:
#     schedule: "* * * * *"               # Cada minuto
#   field_obsolete_threshold: ""         # No filtrar por obsolescencia

# ========================================
# CONFIGURACIÃ“N TIPO B: ESTACIÃ“N METEOROLÃ“GICA
# ========================================
# Use case: MÃºltiples sensores independientes
#
# measurements:
#   include: [WeatherStation]
#   specific:
#     WeatherStation:
#       fields:
#         include: [
#           temperature,     # T01
#           humidity,        # T02
#           pressure,        # T03
#           wind_speed,      # T04
#           wind_direction,  # T05
#           rainfall,        # T06
#           uv_index,        # T07
#           solar_radiation  # T08
#         ]
#
# options:
#   backup_mode: incremental
#   parallel_workers: 8                  # Un worker por sensor
#   incremental:
#     schedule: "*/5 * * * *"             # Cada 5 minutos

# ========================================
# CONFIGURACIÃ“N TIPO C: BACKUP HISTÃ“RICO MASIVO
# ========================================
# Use case: Migrar datos histÃ³ricos de un aÃ±o completo
#
# measurements:
#   include: []                          # Todas las mediciones
#
# options:
#   backup_mode: range
#   parallel_workers: 16                 # MÃ¡ximo paralelismo
#   range:
#     start_date: "2023-01-01T00:00:00Z"
#     end_date: "2023-12-31T23:59:59Z"
#   days_of_pagination: 1                # Chunks pequeÃ±os para seguridad

# ========================================
# CONFIGURACIÃ“N TIPO D: MÃšLTIPLES MEDICIONES
# ========================================
# Use case: Varias mediciones con campos especÃ­ficos cada una
#
# measurements:
#   include: [cpu, memory, disk, network]
#   specific:
#     cpu:
#       fields:
#         include: [usage_user, usage_system, usage_idle]
#     memory:
#       fields:
#         include: [used, available, percent]
#     disk:
#       fields:
#         include: [used_percent, free]
#     network:
#       fields:
#         include: [bytes_sent, bytes_recv]
#
# options:
#   parallel_workers: 6                  # Balance para mÃºltiples mediciones
#   incremental:
#     schedule: "0 */6 * * *"             # Cada 6 horas

# =============================================
# PASOS PARA CONFIGURAR TU BACKUP
# =============================================
#
# 1. COPIA ESTE TEMPLATE:
#    cp backup_config.yaml.template mi_configuracion.yaml
#
# 2. CONFIGURA LOS SERVIDORES:
#    - Ajusta las URLs de source y destination
#    - Configura autenticaciÃ³n si es necesaria
#
# 3. DEFINE QUÃ‰ RESPALDAR:
#    - Especifica bases de datos en source.databases
#    - Configura mediciones en measurements.include/exclude
#    - Define campos especÃ­ficos en measurements.specific
#
# 4. CONFIGURA PARALELIZACIÃ“N:
#    - Cuenta cuÃ¡ntos campos vas a procesar
#    - Configura parallel_workers apropiadamente
#    - Para empezar usa parallel_workers: 1
#
# 5. CONFIGURA HORARIOS:
#    - Para backup continuo: incremental.schedule con cron
#    - Para backup Ãºnico: range con fechas especÃ­ficas
#
# 6. PERSONALIZA LOGGING:
#    - Cambia loki.tags.config al nombre de tu archivo
#    - Ajusta log_level segÃºn necesidades
#
# 7. VALIDA LA CONFIGURACIÃ“N:
#    python main.py --validate-only
#
# 8. EJECUTA EL BACKUP:
#    python main.py --config /config --verbose
#
# 9. MONITOREA LOS LOGS:
#    tail -f /var/log/backup_influxdb/mi_configuracion.yaml/backup.log
#
# 10. REVISA MÃ‰TRICAS:
#    grep "Parallelization metrics" logs/*.log

# =============================================
# Â¿NECESITAS AYUDA?
# =============================================
#
# ğŸ“– DocumentaciÃ³n completa: README.md
# ğŸ”§ Configuraciones ejemplo: config/irr.yaml, config/temp.yaml
# ğŸ› Troubleshooting: Ver secciÃ³n "Troubleshooting" en README.md
# ğŸ“Š MÃ©tricas: Dashboard Grafana en http://localhost:3000
#
# COMANDO ÃšTILES:
# - Validar: python main.py --validate-only
# - Ejecutar: python main.py --config /config
# - Debug: python main.py --config /config --verbose
# - Ver logs: tail -f /var/log/backup_influxdb/*/backup.log
#
# =============================================
